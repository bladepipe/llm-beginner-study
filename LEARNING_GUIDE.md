# LEARNING_GUIDE.md â€” Bigram æ¨¡å‹é€è¡Œæ•™å­¦ï¼ˆä¸­è‹±åŒè¯­ Â· å¸¦è¡Œå·ï¼‰

## ğŸ”‘ æ–°æ‰‹æœ€åº”æŒæ¡çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜

### 1. ä»€ä¹ˆæ˜¯ Bigram æ¨¡å‹ï¼Ÿ
A Bigram model is a language model that predicts the next character based *only* on the previous one. Formally, it models: `P('e' | 'h')`
For example, if after the letter `'h'` the letter `'e'` appears 60% of the time in training text, the model captures exactly that probability.

Bigram æ¨¡å‹æ˜¯ä¸€ç§è¯­è¨€æ¨¡å‹ï¼Œå®ƒä»…æ ¹æ®å‰ä¸€ä¸ªå­—ç¬¦é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚å½¢å¼ä¸Šï¼Œå®ƒå»ºæ¨¡çš„æ˜¯ï¼š
â€ƒâ€ƒ`P('e' | 'h')`ï¼ˆå³â€œåœ¨ `'h'` ä¹‹åå‡ºç° `'e'` çš„æ¦‚ç‡â€ï¼‰
ä¾‹å¦‚ï¼Œè‹¥åœ¨è®­ç»ƒæ–‡æœ¬ä¸­ï¼Œå­—æ¯ `'h'` åé¢å‡ºç° `'e'` çš„é¢‘ç‡ä¸º 60%ï¼Œè¯¥æ¨¡å‹å°±ç²¾ç¡®æ•è·è¿™ä¸€æ¦‚ç‡ã€‚

### 2. å®ƒå¦‚ä½•â€œå­¦ä¹ â€ï¼Ÿ
It doesnâ€™t use gradients or neural networks. It simply:
- Scans the training text (e.g., Shakespeare)
- Counts how often each pair (`'h'â†’'e'`, `'e'â†’'l'`, etc.) appears
- Converts those counts into probabilities (e.g., `'h'â†’'e'`: 12 times out of 20 total `'h'` appearances = 0.6)

å®ƒä¸ä½¿ç”¨æ¢¯åº¦æˆ–ç¥ç»ç½‘ç»œã€‚å®ƒåªåšä¸‰ä»¶äº‹ï¼š
- æ‰«æè®­ç»ƒæ–‡æœ¬ï¼ˆå¦‚èå£«æ¯”äºšæˆå‰§ï¼‰
- ç»Ÿè®¡æ¯ä¸€å¯¹å­—ç¬¦ï¼ˆå¦‚ `'h'â†’'e'`ã€`'e'â†’'l'` ç­‰ï¼‰å‡ºç°çš„æ¬¡æ•°
- å°†è¿™äº›è®¡æ•°è½¬åŒ–ä¸ºæ¦‚ç‡ï¼ˆä¾‹å¦‚ï¼š`'h'` å…±å‡ºç° 20 æ¬¡ï¼Œå…¶ä¸­ 12 æ¬¡åé¢æ˜¯ `'e'` â†’ `P('e'|'h') = 12/20 = 0.6`ï¼‰

### 3. å®ƒå¦‚ä½•ç”Ÿæˆæ–‡æœ¬ï¼Ÿ
Given a starting character (e.g., `'t'`), it:
- Looks up the probability table for `'t'` â†’ e.g., `'h':0.62`, `'e':0.12`, `' ':0.09`
- Randomly picks the next character *weighted by those probabilities*
- Repeats: now `'h'` becomes the context, looks up its row, samples againâ€¦

ç»™å®šä¸€ä¸ªèµ·å§‹å­—ç¬¦ï¼ˆå¦‚ `'t'`ï¼‰ï¼Œå®ƒä¼šï¼š
- æŸ¥è¯¢ `'t'` å¯¹åº”çš„æ¦‚ç‡è¡¨ â†’ ä¾‹å¦‚ `'h':0.62`ã€`'e':0.12`ã€`' ':0.09`
- æŒ‰è¿™äº›æ¦‚ç‡åŠ æƒéšæœºé€‰å–ä¸‹ä¸€ä¸ªå­—ç¬¦
- é‡å¤è¯¥è¿‡ç¨‹ï¼šæ­¤æ—¶ `'h'` æˆä¸ºæ–°ä¸Šä¸‹æ–‡ï¼ŒæŸ¥è¯¢å…¶å¯¹åº”è¡Œï¼Œå†æ¬¡é‡‡æ ·â€¦â€¦

â†’ This is **autoregressive generation**, the core idea behind GPT.
â†’ è¿™å°±æ˜¯**è‡ªå›å½’ç”Ÿæˆ**ï¼Œä¹Ÿæ˜¯ GPT çš„æ ¸å¿ƒæ€æƒ³ã€‚